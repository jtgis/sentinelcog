name: Weekly Sentinel-2 Change Detection (New Brunswick)

on:
  schedule:
    - cron: "0 15 * * 1"   # Mondays 15:00 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  s2_change_detection:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install \
            numpy \
            rasterio \
            rioxarray \
            xarray \
            dask[complete] \
            pystac-client \
            stackstac \
            shapely \
            pillow

      - name: Prepare folders
        run: mkdir -p outputs tmp docs

      - name: Run Sentinel-2 change detection (COG, robust search)
        shell: bash
        run: |
          python <<'PY'
          import os, glob, json, warnings
          import datetime as dt
          import numpy as np
          import rasterio as rio
          from rasterio.enums import Resampling
          import rioxarray  # needed for .rio accessor
          from shapely.geometry import box, mapping
          from pystac_client import Client
          import stackstac
          from PIL import Image

          warnings.filterwarnings("ignore")

          # ----------------- Config -----------------
          BBOX = (-69.2, 44.5, -63.6, 48.2)   # New Brunswick (approx)
          RES_M = 60                          # use 20/10 for finer (heavier)
          OUTDIR = "outputs"
          COLLECTION_CANDIDATES = ["sentinel-2-l2a", "sentinel-s2-l2a-cogs"]
          DAY_WINDOWS = [14, 21, 30, 45, 60]
          CLOUD_THRESHOLDS = [30, 60, 100]
          # ------------------------------------------

          def find_items():
            stac = Client.open("https://earth-search.aws.element84.com/v1")
            geom = mapping(box(*BBOX))
            for coll in COLLECTION_CANDIDATES:
              for days in DAY_WINDOWS:
                for cloud in CLOUD_THRESHOLDS:
                  end = dt.date.today().isoformat()
                  start = (dt.date.today() - dt.timedelta(days=days)).isoformat()
                  search = stac.search(
                    collections=[coll],
                    intersects=geom,
                    datetime=f"{start}/{end}",
                    query={"eo:cloud_cover": {"lt": cloud}}
                  )
                  items = list(search.get_items())
                  if items:
                    return coll, days, cloud, items
            return None, None, None, []

          coll, days, cloud, items = find_items()

          if not items:
            print("No Sentinel-2 items found even after widening search (up to 60 days, 100% clouds).")
            # Write a small note so the viewer has something to show
            with open(os.path.join("docs", "index.html"), "w") as f:
              f.write("<!doctype html><meta charset='utf-8'><body><p>No new Sentinel-2 data found yet. Try again next run.</p>")
            # also make a minimal latest.json for clarity
            with open(os.path.join("docs", "latest.json"), "w") as f:
              json.dump({"ndvi_cog": None, "change_cog": None}, f)
            # Exit 0 so the job doesn't fail
            raise SystemExit(0)

          print(f"Using collection='{coll}', lookback={days}d, cloud<{cloud}%, items={len(items)}")

          # Group by acquisition date (UTC yyyy-mm-dd)
          from collections import defaultdict
          by_date = defaultdict(list)
          for it in items:
            d = it.properties["datetime"][:10]
            by_date[d].append(it)

          picked_date = sorted(by_date)[-1]
          picked_items = by_date[picked_date]
          print(f"Picked date {picked_date} with {len(picked_items)} items")

          # Build stack for B04/B08
          assets = ["B04", "B08"]
          da = stackstac.stack(
            picked_items,
            assets=assets,
            resolution=RES_M,
            bounds=BBOX,
            chunks={"time": 1, "x": 1024, "y": 1024},
            dtype="uint16"
          )

          arr = da.astype("float32") / 10000.0
          mosaic = arr.median(dim="time", skipna=True)
          red = mosaic.sel(band="B04")
          nir = mosaic.sel(band="B08")

          ndvi = (nir - red) / (nir + red + 1e-6)
          ndvi = ndvi.clip(-1, 1)
          ndvi = ndvi.rio.write_crs(da.rio.crs)
          ndvi = ndvi.rio.write_transform(da.rio.transform())

          ndvi_cog = os.path.join(OUTDIR, f"nb_ndvi_{picked_date}.tif")
          ndvi.rio.to_raster(
            ndvi_cog,
            driver="COG",
            compress="LZW",
            dtype="float32",
            BLOCKSIZE=512,
            OVERVIEWS="AUTO"
          )

          # Quicklook PNG
          def save_png(data_xr, path):
            a = data_xr.compute().values
            scaled = ((a + 1) / 2 * 255).astype(np.uint8)  # [-1,1] -> [0,255]
            Image.fromarray(scaled).save(path)

          save_png(ndvi, os.path.join(OUTDIR, f"nb_ndvi_{picked_date}.png"))

          # Change vs previous
          prev = sorted(glob.glob(os.path.join(OUTDIR, "nb_ndvi_*.tif")))
          prev = [p for p in prev if picked_date not in p]
          change_cog_path = None
          if prev:
            prev_path = prev[-1]
            with rio.open(prev_path) as src_prev, rio.open(ndvi_cog) as src_cur:
              prev_a_
              
